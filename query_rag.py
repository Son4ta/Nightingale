# query_rag.py (Refactored to show context)

import os
from dotenv import load_dotenv

from langchain.retrievers import BM25Retriever, EnsembleRetriever
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

# --- 1. é…ç½®åŒºåŸŸ (å·²æŒ‰æ‚¨çš„è¦æ±‚æ›´æ–°) ---
load_dotenv()

SILICONFLOW_API_KEY = os.getenv("SILICONFLOW_API_KEY")
if not SILICONFLOW_API_KEY:
    raise ValueError("SILICONFLOW_API_KEY not found in environment variables.")

# æ›´æ–°ä¸º SiliconFlow çš„ v1 åœ°å€
SILICONFLOW_BASE_URL = "https://api.siliconflow.cn/v1"

# æ›´æ–°ä¸º Qwen3 ç³»åˆ—æ¨¡å‹
EMBEDDING_MODEL = "Qwen/Qwen3-Embedding-8B"
LLM_MODEL = "Qwen/Qwen3-30B-A3B"

# æ›´æ–°ä¸ºæ–°çš„ç´¢å¼•è·¯å¾„
FAISS_INDEX_PATH = "knowledge_base"
RETRIEVAL_TOP_K = 5

# --- 2. RAG æ ¸å¿ƒé€»è¾‘ (å·²å‡çº§ä¸ºæ··åˆæ£€ç´¢) ---

print("Initializing models and retrievers...")
embeddings = OpenAIEmbeddings(
    model=EMBEDDING_MODEL,
    openai_api_key=SILICONFLOW_API_KEY,
    openai_api_base=SILICONFLOW_BASE_URL
)

# åŠ è½½FAISSå‘é‡æ£€ç´¢å™¨
try:
    db = FAISS.load_local(FAISS_INDEX_PATH, embeddings, allow_dangerous_deserialization=True)
    faiss_retriever = db.as_retriever(search_kwargs={"k": RETRIEVAL_TOP_K})
except Exception as e:
    print(f"Fatal: Could not load FAISS index from '{FAISS_INDEX_PATH}'. Error: {e}")
    exit()

# !!! æ–°å¢ï¼šè®¾ç½®å…³é”®è¯æ£€ç´¢å™¨ (BM25) !!!
# BM25 éœ€è¦åŸå§‹æ–‡æ¡£ï¼Œæˆ‘ä»¬ä» FAISS çš„ docstore ä¸­è·å–
# è¿™å‡è®¾ FAISS ç´¢å¼•æ˜¯ç”¨ from_documents æ„å»ºçš„ï¼Œæˆ‘ä»¬çš„è„šæœ¬æ­£æ˜¯å¦‚æ­¤
doc_list = list(db.docstore._dict.values())

print("Initializing BM25 keyword retriever...")
bm25_retriever = BM25Retriever.from_documents(doc_list)
bm25_retriever.k = RETRIEVAL_TOP_K

# å®šä¹‰æœ€ç»ˆçš„æ£€ç´¢å™¨
print("Initializing Ensemble (Hybrid) Retriever...")
ensemble_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, faiss_retriever],
    weights=[0.5, 0.5]  # æƒé‡å¯ä»¥è°ƒæ•´ï¼Œè¿™é‡Œæ˜¯å…³é”®è¯å’Œè¯­ä¹‰å„å ä¸€åŠ
)


# Prompt æ¨¡æ¿
template = """
ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„è¯¾ç¨‹åŠ©æ•™ï¼Œä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æˆ‘æä¾›çš„ä¸Šä¸‹æ–‡ææ–™æ¥å›ç­”é—®é¢˜ã€‚

**æŒ‡ä»¤**:
1.  **ä¸¥æ ¼ä¾æ®ææ–™**: ä½ çš„å›ç­”å¿…é¡»å®Œå…¨åŸºäºä»¥ä¸‹æä¾›çš„ä¸Šä¸‹æ–‡ææ–™ï¼Œç¦æ­¢ä½¿ç”¨ä»»ä½•å¤–éƒ¨çŸ¥è¯†ã€‚
2.  **ç²¾ç¡®å¼•ç”¨**: å¯¹ä½ å›ç­”ä¸­çš„æ¯ä¸€ä¸ªè§‚ç‚¹æˆ–æ•°æ®ï¼Œéƒ½å¿…é¡»åœ¨å¥æœ«ç”¨ `(æ¥æº: <æ–‡ä»¶å>, é¡µç : <é¡µç >)` çš„æ ¼å¼æ³¨æ˜å‡ºå¤„ã€‚å¦‚æœä¸€ä¸ªè§‚ç‚¹ç»¼åˆäº†å¤šä¸ªæ¥æºï¼Œè¯·å…¨éƒ¨åˆ—å‡ºã€‚
3.  **å…¨é¢è€Œç®€æ´**: ç»¼åˆæ‰€æœ‰ç›¸å…³ä¿¡æ¯ï¼Œç»™å‡ºå…¨é¢è€Œç²¾ç‚¼çš„å›ç­”ã€‚
4.  **æœªçŸ¥åˆ™ç­”æ— **: å¦‚æœä¸Šä¸‹æ–‡ææ–™ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œå¿…é¡»æ˜ç¡®å›ç­”ï¼šâ€œæ ¹æ®æä¾›çš„ææ–™ï¼Œæ— æ³•å›ç­”æ­¤é—®é¢˜ã€‚â€

**ä¸Šä¸‹æ–‡ææ–™**:
---
{context}
---

**é—®é¢˜**: {question}

**ä½ çš„å›ç­”**:
"""
prompt = PromptTemplate.from_template(template)

# åˆå§‹åŒ– LLMï¼Œä½¿ç”¨æµå¼è¾“å‡º
llm = ChatOpenAI(
    model_name=LLM_MODEL,
    openai_api_key=SILICONFLOW_API_KEY,
    openai_api_base=SILICONFLOW_BASE_URL,
    temperature=0.1,
    streaming=True,
    callbacks=[StreamingStdOutCallbackHandler()]
)

def format_docs(docs):
    """æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼Œä»¥ä¾¿æ¸…æ™°åœ°å±•ç¤ºç»™ LLM"""
    return "\n---\n".join(
        f"æ¥æº: {doc.metadata['source']}, é¡µç : {doc.metadata['page']}\nå†…å®¹: {doc.page_content}"
        for doc in docs
    )

# å®šä¹‰ RAG é“¾
rag_chain = (
    {"context": ensemble_retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# --- 3. äº¤äº’å¼æŸ¥è¯¢ (å·²æ›´æ–°ï¼Œä¼šæ˜¾ç¤ºä¸Šä¸‹æ–‡) ---
if __name__ == "__main__":
    print("\n--- RAG Exam Assistant Ready ---")
    print(f"   LLM Model: {LLM_MODEL}")
    print(f"   Embedding Model: {EMBEDDING_MODEL}")
    print("------------------------------------")
    print("Enter your question, or type 'exit' to quit.")
    
    while True:
        question = input("\n[è€ƒè¯•é—®é¢˜] > ")
        if question.lower() == 'exit':
            break
        if not question:
            continue
            
        # æ­¥éª¤ 1: æ£€ç´¢ä¸Šä¸‹æ–‡
        print("\nğŸ” [1. æ­£åœ¨æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡...]")
        retrieved_docs = ensemble_retriever.invoke(question)
        
        # æ­¥éª¤ 2: æ‰“å°æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å†…å®¹
        print("\nğŸ“š [2. å·²æ‰¾åˆ°ä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯:]")
        print("="*40)
        if not retrieved_docs:
            print("   (æœªæ‰¾åˆ°ç›¸å…³ä¸Šä¸‹æ–‡)")
        else:
            for i, doc in enumerate(retrieved_docs):
                source = doc.metadata.get('source', 'Unknown')
                page = doc.metadata.get('page', 'N/A')
                print(f"  [ç‰‡æ®µ {i+1}] æ¥æº: {source}, é¡µç : {page}")
                print(f"  å†…å®¹: {doc.page_content[:250]}...") # æ‰“å°å†…å®¹çš„å‰250ä¸ªå­—ç¬¦ä½œä¸ºé¢„è§ˆ
                print("-"*40)
        
        # æ­¥éª¤ 3: åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ
        print("\nğŸ§  [3. æ­£åœ¨ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...]\n")
        # è°ƒç”¨ RAG é“¾ï¼Œæµå¼å›è°ƒä¼šè‡ªåŠ¨æ‰“å°ç­”æ¡ˆ
        rag_chain.invoke(question)
        print() # åœ¨æµå¼è¾“å‡ºç»“æŸåæ¢è¡Œ
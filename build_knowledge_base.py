# build_knowledge_base.py (Optimized for Corpus Export)

import os
import base64
from PIL import Image
import io
import sys
import json

import fitz  # PyMuPDF
from dotenv import load_dotenv
from openai import OpenAI
from tqdm import tqdm

from langchain_core.documents import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

# --- 1. é…ç½®åŒºåŸŸ ---
load_dotenv()

SILICONFLOW_API_KEY = os.getenv("SILICONFLOW_API_KEY")
if not SILICONFLOW_API_KEY:
    raise ValueError("SILICONFLOW_API_KEY not found in environment variables.")

# å¼€å…³ï¼šæ˜¯å¦å¤„ç†å›¾ç‰‡æè¿°ã€‚APIå¤ªæ…¢æ—¶å¯è®¾ä¸º False
PROCESS_IMAGES = False

SILICONFLOW_BASE_URL = "https://api.siliconflow.cn/v1"

# æ¨¡å‹å’Œè·¯å¾„é…ç½®
EMBEDDING_MODEL = "Qwen/Qwen3-Embedding-8B"
VLM_MODEL = "Qwen/Qwen2.5-VL-32B-Instruct"
CORPUS_DIRECTORY = "./corpus"
FAISS_INDEX_PATH = "knowledge_base"
# !!! æ–°å¢ï¼šå®šä¹‰å¯¼å‡ºè¯­æ–™åº“çš„æ–‡ä»¶è·¯å¾„ !!!
CORPUS_EXPORT_PATH = "exported_corpus.json"

# æ–‡æœ¬åˆ†å—è®¾ç½®
CHUNK_SIZE = 1024
CHUNK_OVERLAP = 256

vlm_client = OpenAI(api_key=SILICONFLOW_API_KEY, base_url=SILICONFLOW_BASE_URL)

# --- 2. è¿›åº¦æ—¥å¿—æ¨¡å— ---
class ProgressLogger:
    """ä¸€ä¸ªç®€å•çš„ç±»ï¼Œç”¨äºåœ¨åŒä¸€è¡ŒåŠ¨æ€æ˜¾ç¤ºä»»åŠ¡è¿›åº¦ã€‚"""
    def start(self, message: str):
        sys.stdout.write(f"âš™ï¸  {message}...")
        sys.stdout.flush()

    def done(self):
        sys.stdout.write("\râœ…  Done.                                  \n")
        sys.stdout.flush()

# --- 3. æ ¸å¿ƒå‡½æ•° (å·²æ›´æ–°) ---

def get_image_description(image_bytes: bytes) -> str:
    base64_image = base64.b64encode(image_bytes).decode('utf-8')
    try:
        response = vlm_client.chat.completions.create(
            model=VLM_MODEL,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çœ‹å›¾è¯´è¯åŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡è¯¦ç»†æè¿°è¿™å¹…å›¾ç‰‡çš„å†…å®¹ï¼Œé‡ç‚¹æè¿°å›¾ä¸­çš„å…³é”®ä¿¡æ¯ã€å›¾è¡¨å’Œæµç¨‹ã€‚"},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                    ]
                }
            ],
            max_tokens=512,
            timeout=120,
        )
        description = response.choices[0].message.content
        return f"[å›¾ç‰‡æè¿°: {description}]"
    except Exception as e:
        tqdm.write(f"\n[Warning] Image description API call failed: {e}. Skipping this image.")
        return "[å›¾ç‰‡å¤„ç†å¤±è´¥]"


def load_pdfs_with_images(directory: str) -> list[Document]:
    all_docs = []
    pdf_files = [f for f in os.listdir(directory) if f.endswith('.pdf')]
    
    for filename in tqdm(pdf_files, desc="Processing PDF files"):
        file_path = os.path.join(directory, filename)
        doc = fitz.open(file_path)
        
        total_images_in_doc = 0
        if PROCESS_IMAGES:
            total_images_in_doc = sum(len(page.get_images(full=True)) for page in doc)
            if total_images_in_doc > 0:
                tqdm.write(f"  ğŸ“„ åœ¨ '{filename}' ä¸­å‘ç° {total_images_in_doc} å¼ å›¾ç‰‡ã€‚")
        
        processed_image_count = 0
        
        for page_num, page in enumerate(doc):
            text = page.get_text("text")
            full_page_content = text
            
            if PROCESS_IMAGES and page.get_images(full=True):
                image_descriptions = []
                for img_index, img in enumerate(page.get_images(full=True)):
                    processed_image_count += 1
                    progress_message = f"\r    -> æ­£åœ¨å¤„ç†ç¬¬ {processed_image_count} / {total_images_in_doc} å¼ å›¾ç‰‡..."
                    sys.stdout.write(progress_message)
                    sys.stdout.flush()
                    
                    xref = img[0]
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    description = get_image_description(image_bytes)
                    image_descriptions.append(description)

                if image_descriptions:
                    full_page_content += "\n\n" + "\n".join(image_descriptions)

            doc_obj = Document(
                page_content=full_page_content,
                metadata={"source": filename, "page": page_num + 1}
            )
            all_docs.append(doc_obj)
        
        if PROCESS_IMAGES and total_images_in_doc > 0:
            sys.stdout.write("\r" + " " * (len(progress_message) + 5) + "\r")
            sys.stdout.flush()
            tqdm.write(f"  âœ”ï¸  '{filename}' ä¸­çš„å›¾ç‰‡å¤„ç†å®Œæ¯•ã€‚")

    return all_docs

# !!! æ–°å¢åŠŸèƒ½ï¼šå°†æå–çš„å®Œæ•´è¯­æ–™ä¿å­˜åˆ°æ–‡ä»¶ !!!
def save_corpus_to_jsonl(documents: list[Document], file_path: str):
    """å°†æ–‡æ¡£åˆ—è¡¨ä»¥ JSONL æ ¼å¼ä¿å­˜åˆ°æ–‡ä»¶ã€‚"""
    with open(file_path, 'w', encoding='utf-8') as f:
        for doc in tqdm(documents, desc=f"Exporting corpus to {file_path}"):
            # æ„å»ºä¸€ä¸ªåŒ…å«å…ƒæ•°æ®å’Œå†…å®¹çš„å­—å…¸
            record = {
                "source": doc.metadata.get("source", "unknown"),
                "page": doc.metadata.get("page", 0),
                "content": doc.page_content
            }
            # å°†å­—å…¸åºåˆ—åŒ–ä¸ºJSONå­—ç¬¦ä¸²å¹¶å†™å…¥æ–‡ä»¶ï¼Œåè·Ÿæ¢è¡Œç¬¦
            f.write(json.dumps(record, ensure_ascii=False) + '\n')

# --- 4. ä¸»æµç¨‹ (å·²æ›´æ–°) ---
if __name__ == "__main__":
    logger = ProgressLogger()
    
    print("Starting knowledge base creation process...")
    if not PROCESS_IMAGES:
        print("ğŸ’¡ Image processing is disabled.")

    logger.start("Step 1: Loading PDFs and processing content")
    documents = load_pdfs_with_images(CORPUS_DIRECTORY)
    logger.done()
    print(f"   â””â”€â”€ Total pages (documents) loaded: {len(documents)}")

    # --- æ–°å¢æ­¥éª¤ï¼šåœ¨åˆ†å—å‰å¯¼å‡ºå®Œæ•´è¯­æ–™ ---
    logger.start(f"Step 2: Exporting full corpus to '{CORPUS_EXPORT_PATH}'")
    save_corpus_to_jsonl(documents, CORPUS_EXPORT_PATH)
    logger.done()
    # --- å¯¼å‡ºæ­¥éª¤ç»“æŸ ---

    logger.start("Step 3: Splitting documents into chunks for RAG")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP
    )
    chunks = text_splitter.split_documents(documents)
    chunks = [chunk for chunk in chunks if chunk.page_content.strip()]
    logger.done()
    print(f"   â””â”€â”€ Total non-empty chunks created: {len(chunks)}")

    logger.start("Step 4: Embedding chunks and building FAISS index")
    embeddings = OpenAIEmbeddings(
        model=EMBEDDING_MODEL,
        openai_api_key=SILICONFLOW_API_KEY,
        openai_api_base=SILICONFLOW_BASE_URL,
    )
    db = FAISS.from_documents(chunks, embeddings)
    logger.done()

    logger.start("Step 5: Saving index to local disk")
    db.save_local(FAISS_INDEX_PATH)
    logger.done()
    
    print(f"\nğŸ‰ Knowledge base build process complete!")
    print(f"   - RAG index saved to '{FAISS_INDEX_PATH}'")
    print(f"   - Full corpus exported to '{CORPUS_EXPORT_PATH}'")
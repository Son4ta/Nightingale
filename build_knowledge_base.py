# build_knowledge_base.py (Final Refactored Version)

import os
import base64
from PIL import Image
import io
from tqdm import tqdm
import sys

import fitz  # PyMuPDF
from dotenv import load_dotenv
from openai import OpenAI

from langchain_core.documents import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

# --- 1. é…ç½®åŒºåŸŸ  ---
load_dotenv()

SILICONFLOW_API_KEY = os.getenv("SILICONFLOW_API_KEY")
if not SILICONFLOW_API_KEY:
    raise ValueError("SILICONFLOW_API_KEY not found in environment variables.")

# å¼€å…³ï¼šæ˜¯å¦å¤„ç†å›¾ç‰‡æè¿°ã€‚APIå¤ªæ…¢æ—¶å¯è®¾ä¸º False
PROCESS_IMAGES = False

SILICONFLOW_BASE_URL = "https://api.siliconflow.cn/v1"

# æ›´æ–°ä¸ºæ–°çš„æ¨¡å‹å’Œè·¯å¾„
EMBEDDING_MODEL = "Qwen/Qwen3-Embedding-8B"
VLM_MODEL = "Qwen/Qwen2.5-VL-32B-Instruct"
CORPUS_DIRECTORY = "./corpus"
FAISS_INDEX_PATH = "knowledge_base"

# æ›´æ–°ä¸ºæ–°çš„åˆ†å—è®¾ç½®
CHUNK_SIZE = 512
CHUNK_OVERLAP = 128

vlm_client = OpenAI(api_key=SILICONFLOW_API_KEY, base_url=SILICONFLOW_BASE_URL)

# --- 2. è¿›åº¦æ—¥å¿—æ¨¡å— ---
class ProgressLogger:
    """ä¸€ä¸ªç®€å•çš„ç±»ï¼Œç”¨äºåœ¨åŒä¸€è¡ŒåŠ¨æ€æ˜¾ç¤ºä»»åŠ¡è¿›åº¦ã€‚"""
    def start(self, message: str):
        sys.stdout.write(f"âš™ï¸  {message}...")
        sys.stdout.flush()

    def done(self):
        sys.stdout.write("\râœ…  Done.                                  \n")
        sys.stdout.flush()

# --- 3. æ ¸å¿ƒå‡½æ•° (å·²æ›´æ–°æ—¥å¿—åŠŸèƒ½) ---

def get_image_description(image_bytes: bytes) -> str:
    base64_image = base64.b64encode(image_bytes).decode('utf-8')
    try:
        response = vlm_client.chat.completions.create(
            model=VLM_MODEL,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çœ‹å›¾è¯´è¯åŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡è¯¦ç»†æè¿°è¿™å¹…å›¾ç‰‡çš„å†…å®¹ï¼Œé‡ç‚¹æè¿°å›¾ä¸­çš„å…³é”®ä¿¡æ¯ã€å›¾è¡¨å’Œæµç¨‹ã€‚"},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                    ]
                }
            ],
            max_tokens=512,
            timeout=120, # ç¨å¾®å¢åŠ è¶…æ—¶æ—¶é—´ä»¥åº”å¯¹å¤§æ¨¡å‹
        )
        description = response.choices[0].message.content
        return f"[å›¾ç‰‡æè¿°: {description}]"
    except Exception as e:
        tqdm.write(f"\n[Warning] Image description API call failed: {e}. Skipping this image.")
        return "[å›¾ç‰‡å¤„ç†å¤±è´¥]"


def load_pdfs_with_images(directory: str) -> list[Document]:
    all_docs = []
    pdf_files = [f for f in os.listdir(directory) if f.endswith('.pdf')]
    
    # ä½¿ç”¨tqdmæ¥æ˜¾ç¤ºæ€»ä½“æ–‡ä»¶å¤„ç†è¿›åº¦
    for filename in tqdm(pdf_files, desc="Processing PDF files"):
        file_path = os.path.join(directory, filename)
        doc = fitz.open(file_path)
        
        # <--- æ–°å¢åŠŸèƒ½: é¢„å…ˆç»Ÿè®¡æ€»å›¾ç‰‡æ•° --->
        total_images_in_doc = 0
        if PROCESS_IMAGES:
            total_images_in_doc = sum(len(page.get_images(full=True)) for page in doc)
            if total_images_in_doc > 0:
                # tqdm.write å¯ä»¥åœ¨ä¸æ‰“ä¹±è¿›åº¦æ¡çš„æƒ…å†µä¸‹æ‰“å°ä¿¡æ¯
                tqdm.write(f"  ğŸ“„ åœ¨ '{filename}' ä¸­å‘ç° {total_images_in_doc} å¼ å›¾ç‰‡ã€‚")
        
        processed_image_count = 0
        # <--- æ–°å¢åŠŸèƒ½ç»“æŸ --->

        for page_num, page in enumerate(doc):
            text = page.get_text("text")
            
            if PROCESS_IMAGES:
                full_page_content = text
                image_list = page.get_images(full=True)
                if image_list:
                    image_descriptions = []
                    for img_index, img in enumerate(image_list):
                        processed_image_count += 1 # <--- æ–°å¢åŠŸèƒ½: æ›´æ–°è®¡æ•°å™¨
                        
                        # <--- æ–°å¢åŠŸèƒ½: æ‰“å°å®æ—¶å›¾ç‰‡å¤„ç†è¿›åº¦ --->
                        progress_message = f"\r    -> æ­£åœ¨å¤„ç†ç¬¬ {processed_image_count} / {total_images_in_doc} å¼ å›¾ç‰‡..."
                        sys.stdout.write(progress_message)
                        sys.stdout.flush()
                        # <--- æ–°å¢åŠŸèƒ½ç»“æŸ --->
                        
                        xref = img[0]
                        base_image = doc.extract_image(xref)
                        image_bytes = base_image["image"]
                        description = get_image_description(image_bytes)
                        image_descriptions.append(description)

                    if image_descriptions:
                        full_page_content += "\n\n" + "\n".join(image_descriptions)
            else:
                full_page_content = text
            
            doc_obj = Document(
                page_content=full_page_content,
                metadata={"source": filename, "page": page_num + 1}
            )
            all_docs.append(doc_obj)
        
        # <--- æ–°å¢åŠŸèƒ½: æ¸…ç†å½“å‰æ–‡ä»¶çš„è¿›åº¦è¡Œ --->
        if PROCESS_IMAGES and total_images_in_doc > 0:
            sys.stdout.write("\r" + " " * (len(progress_message) + 5) + "\r") # æ¸…é™¤è¡Œ
            sys.stdout.flush()
            tqdm.write(f"  âœ”ï¸  '{filename}' ä¸­çš„å›¾ç‰‡å¤„ç†å®Œæ¯•ã€‚")
        # <--- æ–°å¢åŠŸèƒ½ç»“æŸ --->

    return all_docs

# --- 4. ä¸»æµç¨‹ (ä¿æŒä¸å˜) ---
if __name__ == "__main__":
    logger = ProgressLogger()
    
    print("Starting knowledge base creation process...")
    if not PROCESS_IMAGES:
        print("ğŸ’¡ Image processing is disabled.")

    logger.start("Step 1: Loading PDFs and processing content")
    documents = load_pdfs_with_images(CORPUS_DIRECTORY)
    logger.done()
    print(f"   â””â”€â”€ Total pages loaded as documents: {len(documents)}")

    logger.start("Step 2: Splitting documents into chunks")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP
    )
    chunks = text_splitter.split_documents(documents)
    chunks = [chunk for chunk in chunks if chunk.page_content.strip()]
    logger.done()
    print(f"   â””â”€â”€ Total non-empty chunks created: {len(chunks)}")

    logger.start("Step 3: Embedding chunks and building FAISS index")
    embeddings = OpenAIEmbeddings(
        model=EMBEDDING_MODEL,
        openai_api_key=SILICONFLOW_API_KEY,
        openai_api_base=SILICONFLOW_BASE_URL,
    )
    db = FAISS.from_documents(chunks, embeddings)
    logger.done()

    logger.start("Step 4: Saving index to local disk")
    db.save_local(FAISS_INDEX_PATH)
    logger.done()
    
    print(f"\nğŸ‰ Knowledge base build process complete! Index saved to '{FAISS_INDEX_PATH}'.")